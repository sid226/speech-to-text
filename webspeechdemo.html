<!DOCTYPE html>
<meta charset="utf-8">
<title>Web Speech API Demo</title>
<head>
  <link rel="stylesheet" href="style.css">
</head>


<h1 class="center" id="headline">
  <a href="">
    cloud Speech API</a> Demonstration</h1>


  <div>
      <button id="record_button" onclick="recordAndStream()">
        <img id="start_img" src="mic.gif" alt="Start"></button>
    </div>
    
    <button id="stop" onclick="stopStream()">Stop</button>

    
<div id="info">
  <p id="info_start">Click on the microphone icon and begin speaking.</p>
  <p id="info_speak_now">Speak now.</p>
  <p id="info_no_speech">No speech was detected. You may need to adjust your
    <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892">
      microphone settings</a>.</p>
  <p id="info_no_microphone" style="display:none">
    No microphone was found. Ensure that a microphone is installed and that
    <a href="//support.google.com/chrome/bin/answer.py?hl=en&amp;answer=1407892">
    microphone settings</a> are configured correctly.</p>
  <p id="info_allow">Click the "Allow" button above to enable your microphone.</p>
  <p id="info_denied">Permission to use microphone was denied.</p>
  <p id="info_blocked">Permission to use microphone is blocked. To change,
    go to chrome://settings/contentExceptions#media-stream</p>
  <p id="info_upgrade">Web Speech API is not supported by this browser.
     Upgrade to <a href="//www.google.com/chrome">Chrome</a>
     version 25 or later.</p>
</div>
 

  <!-- Original link //www.WebRTC-Experiment.com/RecordRTC.js -->
  <script src="RecordRTC.js"></script>

  <script src="binary.js"></script>


<script>
var mediaStream = null;

 var client = new BinaryClient('ws://localhost:9001');

client.on('open', function() {
  // for the sake of this example let's put the stream in the window
  console.log("ws connected!!");
  window.Stream = client.createStream();
}

);

function convertFloat32ToInt16(buffer) {
  l = buffer.length;
  buf = new Int16Array(l);
  while (l--) {
    buf[l] = Math.min(1, buffer[l])*0x7FFF;
  }
  return buf.buffer;
}

function initializeRecorder(stream) {
  mediaStream = stream;
            mediaStream.stop = function () {
                this.getAudioTracks().forEach(function (track) {
                    track.stop();
                });
                // this.getVideoTracks().forEach(function (track) { //in case... :)
                //     track.stop();
                // });
            };

  var audioContext = window.AudioContext;
  var context = new audioContext();
  var audioInput = context.createMediaStreamSource(stream);
  var bufferSize = 2048;
  // create a javascript node
  var recorder = context.createScriptProcessor(2048, 1, 1);
  // specify the processing function
  recorder.onaudioprocess = recorderProcess;
  // connect stream to our recorder
  audioInput.connect(recorder);
  // connect our recorder to the previous destination
  recorder.connect(context.destination);
}

function recorderProcess(e) {
  var left = e.inputBuffer.getChannelData(0);
  window.Stream.write(convertFloat32ToInt16(left));
}

function onError(err) {
  console.log("onError: ",err);

}


var recordAndStream=function () {
  var session = {
  audio: true,
  video: false
};
var recordRTC = null;
navigator.getUserMedia(session, initializeRecorder, onError);


};


var stopStream=function () {  
  //stop recording
  mediaStream.stop();
  //close ws connection
  client.close()
};



</script>


